{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRanker\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from adapt.instance_based import KLIEP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "from sklearn.cross_decomposition import PLSSVD\n",
    "from operator import itemgetter\n",
    "def softmax(x):\n",
    "    return(np.exp(x)/np.exp(x).sum())\n",
    "\n",
    "def my_custom_loss_func_exp(y_true, y_pred):\n",
    "    return spearmanr(np.exp(y_true), np.exp(y_pred)).correlation  \n",
    "\n",
    "def my_custom_loss_func(y_true, y_pred):\n",
    "    #y_pred = np.exp(np.array(y_pred))\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    return np.corrcoef(y_true,y_pred)[0][1]\n",
    "\n",
    "def select_columns(X, y, test_size = 0.33, size_features= 30, state = 100):\n",
    "    dic = dict({})\n",
    "    for i in range(100,100+state):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=i)\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        all_corr = []\n",
    "        for i in range(X_train.shape[1]):\n",
    "            cor = my_custom_loss_func(y_train,X_train[:,i])\n",
    "            all_corr.append(cor)\n",
    "            \n",
    "        all_corr = np.array(all_corr)\n",
    "        cols = np.argsort(all_corr)[::-1]\n",
    "        cols_keep = cols[:size_features]\n",
    "        for i in cols_keep:\n",
    "            if(i in dic):\n",
    "                dic[i]+=1\n",
    "            else:\n",
    "                dic[i] = 1\n",
    "   \n",
    "    s = sorted(dic.items(), key=itemgetter(1),reverse=1)\n",
    "    print(s)\n",
    "    cols_keep = []\n",
    "    for i in range(size_features):\n",
    "        cols_keep.append(s[i][0])\n",
    "    return np.array(cols_keep)\n",
    "\n",
    "def evaluate_model_mean(X, y, model, stratify ,  test_size=0.33, loss = my_custom_loss_func, state = 100, size_features = 30):\n",
    "    \n",
    "    score = []\n",
    "    for i in range(state):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=i, stratify=stratify)\n",
    "        \n",
    "        '''\n",
    "        mask = (X_test['COUNTRY']==-1)\n",
    "        X_test_FR = X_test[mask].copy()\n",
    "        y_train = np.array(y_train)\n",
    "        y_test_FR = np.array(y_test)[np.array(mask)].copy()\n",
    "        \n",
    "        \n",
    "        mask = (X_test['COUNTRY']==1)\n",
    "        X_test_DE = X_test[mask].copy()\n",
    "        y_test_DE = np.array(y_test)[np.array(mask)].copy()\n",
    "        '''\n",
    "    \n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        '''\n",
    "        X_test_FR = np.array(X_test_FR)\n",
    "        X_test_DE = np.array(X_test_DE)\n",
    "        '''\n",
    "        #model_pca = PCA(n_components=X_train.shape[1])\n",
    "        #model_pca.fit(X_train)\n",
    "        #X_train = model_pca.transform(X_train)\n",
    "        #X_test = model_pca.transform(X_test)\n",
    "                \n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        train_score = loss(y_train, model.predict(X_train))\n",
    "        y_predict = model.predict(X_test)\n",
    "        test_score = loss(y_test , y_predict.reshape(-1))\n",
    "        '''\n",
    "        y_predict_FR = model.predict(X_test_FR)\n",
    "        test_score_FR = loss(np.array(y_test_FR) , y_predict_FR.reshape(-1))\n",
    "        \n",
    "        y_predict_DE = model.predict(X_test_DE)\n",
    "        test_score_DE = loss(np.array(y_test_DE) , y_predict_DE.reshape(-1))\n",
    "        '''\n",
    "        score.append([test_score])#,test_score_FR,test_score_DE])\n",
    "        \n",
    "    return np.mean(np.array(score),axis=0)\n",
    "\n",
    "\n",
    "def evaluate_model_mean_lgb(X, y, model, stratify ,  test_size=0.33, loss = my_custom_loss_func, state = 100, size_features = 30):\n",
    "\n",
    "    score = []\n",
    "    for i in range(state):\n",
    "        import lightgbm as lgbm\n",
    "\n",
    "        X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X, y, test_size=0.3,random_state=i, stratify=stratify)\n",
    "        X_train_m, X_val_m, y_train_m, y_val_m = train_test_split(X_train_m, y_train_m, test_size=0.2,random_state=i)\n",
    "\n",
    "        lgbm_parameters ={\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': 0.0941884136011224,\n",
    "        'num_leaves': 180,\n",
    "        'max_depth': 12,\n",
    "        'min_data_in_leaf': 200,\n",
    "        'lambda_l1': 0.01,\n",
    "        'lambda_l2': 1,\n",
    "        'min_gain_to_split': 8.756413243587552,\n",
    "        'bagging_fraction': 0.6000000000000001,\n",
    "        'bagging_freq': 1,\n",
    "        'feature_fraction': 0.5}\n",
    "\n",
    "        model = lgbm.LGBMRegressor(objective=\"regression\", **lgbm_parameters)\n",
    "        model.fit(\n",
    "            X_train_m,\n",
    "            y_train_m,\n",
    "            eval_set=[(X_val_m,y_val_m)],\n",
    "            eval_metric=\"l1\",\n",
    "            early_stopping_rounds=100\n",
    "        )\n",
    "\n",
    "        X_train_m = np.array(X_train_m)\n",
    "        X_test_m = np.array(X_test_m)\n",
    "        \n",
    "        train_score = loss(y_train_m, model.predict(X_train_m))\n",
    "        y_predict = model.predict(X_test_m)\n",
    "        test_score = loss(y_test_m , y_predict.reshape(-1))\n",
    "        \n",
    "        score.append([test_score])\n",
    "        \n",
    "    return np.mean(np.array(score),axis=0)\n",
    "\n",
    "\n",
    "def evaluate_model_mean_all(X, y, model, stratify ,  test_size=0.33, loss = my_custom_loss_func, state = 100, size_features = 30):\n",
    "    \n",
    "    score = []\n",
    "    for i in range(state):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=i, stratify=stratify)\n",
    "        \n",
    "        \n",
    "        mask = (X_test['COUNTRY']==-1)\n",
    "        X_test_FR = X_test[mask].copy()\n",
    "        y_train = np.array(y_train)\n",
    "        y_test_FR = np.array(y_test)[np.array(mask)].copy()\n",
    "        \n",
    "        \n",
    "        mask = (X_test['COUNTRY']==1)\n",
    "        X_test_DE = X_test[mask].copy()\n",
    "        y_test_DE = np.array(y_test)[np.array(mask)].copy()\n",
    "      \n",
    "    \n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "      \n",
    "        X_test_FR = np.array(X_test_FR)\n",
    "        X_test_DE = np.array(X_test_DE)\n",
    "      \n",
    "        #model_pca = PCA(n_components=X_train.shape[1])\n",
    "        #model_pca.fit(X_train)\n",
    "        #X_train = model_pca.transform(X_train)\n",
    "        #X_test = model_pca.transform(X_test)\n",
    "                \n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        train_score = loss(y_train, model.predict(X_train))\n",
    "        y_predict = model.predict(X_test)\n",
    "        test_score = loss(y_test , y_predict.reshape(-1))\n",
    "        \n",
    "        y_predict_FR = model.predict(X_test_FR)\n",
    "        test_score_FR = loss(np.array(y_test_FR) , y_predict_FR.reshape(-1))\n",
    "        \n",
    "        y_predict_DE = model.predict(X_test_DE)\n",
    "        test_score_DE = loss(np.array(y_test_DE) , y_predict_DE.reshape(-1))\n",
    "      \n",
    "        score.append([test_score,test_score_FR,test_score_DE])\n",
    "        \n",
    "    return np.mean(np.array(score),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "X_train = pd.read_csv( path + 'X_train.csv')\n",
    "Y_train = pd.read_csv(path + 'Y_train.csv')\n",
    "X_test = pd.read_csv(path + 'X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(X_train, Y_train, on=['ID'])\n",
    "all_data = data.copy()\n",
    "all_data['train'] = 1\n",
    "all_data = pd.concat([all_data,X_test])\n",
    "all_data['TARGET'] = all_data['TARGET'].fillna(0)\n",
    "all_data['train'] = all_data['train'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def regress_var(df, x_columns, y_column, model, out = True):\n",
    "    temp = df.dropna().copy()\n",
    "    X = np.array(temp[x_columns])\n",
    "    y = np.array(temp[y_column])\n",
    "    model.fit(X,y)\n",
    "    if(out):\n",
    "        print(\"Model score\", model.score(X,y))\n",
    "    return df.apply(lambda row: model.predict(np.array(row[x_columns]).reshape(-1,len(x_columns)))[0] if(np.isnan(row[y_column])) else row[y_column], axis=1)\n",
    "\n",
    "\n",
    "def clean_knn(all_data_clean, k =5 ):\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    remove_columns = ['ID','DAY_ID','TARGET','train']\n",
    "    keep = all_data_clean.columns.difference(remove_columns)\n",
    "    all_data_clean[keep] = imputer.fit_transform(all_data_clean[keep])\n",
    "    return all_data_clean\n",
    "    \n",
    "def clean_regression(all_data_clean):\n",
    "    \n",
    "    #all_data_clean['DE_FR_EXCHANGE'] = all_data_clean['DE_FR_EXCHANGE'].fillna(0)\n",
    "    #all_data_clean['FR_DE_EXCHANGE'] = all_data_clean['FR_DE_EXCHANGE'].fillna(0)\n",
    "    \n",
    "    all_data_clean['DE_FR_EXCHANGE'] = all_data_clean['DE_FR_EXCHANGE'].fillna(all_data_clean['DE_FR_EXCHANGE'].mean(numeric_only=True))\n",
    "    all_data_clean['FR_DE_EXCHANGE'] = all_data_clean['FR_DE_EXCHANGE'].fillna(all_data_clean['FR_DE_EXCHANGE'].mean(numeric_only=True))\n",
    "    \n",
    "    x_columns = ['DE_FR_EXCHANGE']\n",
    "    y_column = 'DE_NET_EXPORT'\n",
    "    all_data_clean[y_column] = regress_var(all_data_clean, x_columns, y_column, LinearRegression(), out=True)\n",
    "    all_data_clean['DE_NET_IMPORT'] = - all_data_clean['DE_NET_EXPORT']\n",
    "    \n",
    "    x_columns = ['FR_DE_EXCHANGE']\n",
    "    y_column = 'FR_NET_EXPORT'\n",
    "    all_data_clean[y_column] = regress_var(all_data_clean, x_columns, y_column, LinearRegression(), out=True)\n",
    "    all_data_clean['FR_NET_IMPORT'] = - all_data_clean['FR_NET_EXPORT']\n",
    "    \n",
    "    all_data_clean = all_data_clean.fillna(all_data_clean.mean(numeric_only=True))\n",
    "    \n",
    "    return all_data_clean\n",
    "\n",
    "def remove_features(all_data_clean):\n",
    "    \n",
    "    all_data_clean = all_data_clean.drop(['DE_FR_EXCHANGE', 'FR_NET_IMPORT','DE_NET_IMPORT'],axis=1)\n",
    "    all_data_clean['FR_NET_EXPORT'] -= all_data_clean['FR_DE_EXCHANGE']\n",
    "    all_data_clean['DE_NET_EXPORT'] += all_data_clean['FR_DE_EXCHANGE']\n",
    "    \n",
    "    \n",
    "    all_data_clean['DE_CONSUMPTION_RENEWABLE'] = all_data_clean['DE_CONSUMPTION'] - all_data_clean['DE_RESIDUAL_LOAD']\n",
    "    all_data_clean['FR_CONSUMPTION_RENEWABLE'] = all_data_clean['FR_CONSUMPTION'] - all_data_clean['FR_RESIDUAL_LOAD']\n",
    "\n",
    "    \n",
    "    #all_data_clean = all_data_clean.rename(columns={'DE_CONSUMPTION':'DE_CONSUMPTION_RENEWABLE', 'FR_CONSUMPTION':'FR_CONSUMPTION_RENEWABLE' })\n",
    "    \n",
    "    all_data_clean['DE_FLOW_GAS'] = all_data_clean['DE_GAS']*all_data_clean['GAS_RET']\n",
    "    all_data_clean['DE_FLOW_COAL'] = all_data_clean['DE_COAL']*all_data_clean['COAL_RET']\n",
    "    all_data_clean['DE_FLOW_LIGNITE'] = all_data_clean['DE_LIGNITE']*all_data_clean['CARBON_RET']\n",
    "\n",
    "\n",
    "    all_data_clean['FR_FLOW_GAS'] = all_data_clean['FR_GAS']*all_data_clean['GAS_RET']\n",
    "    all_data_clean['FR_FLOW_COAL'] = all_data_clean['FR_COAL']*all_data_clean['COAL_RET']\n",
    "    \n",
    "    return all_data_clean\n",
    "\n",
    "def add_clusters(k, all_data_clean,cols,c):\n",
    "    from sklearn.cluster import KMeans\n",
    "    X_season = all_data_clean[cols]\n",
    "    #all_data_clean = all_data_clean.drop(cols,axis=1)\n",
    "    kmeans = KMeans(n_clusters=k,random_state = 0).fit(np.array(X_season))\n",
    "    all_data_clean[c] = kmeans.predict(np.array(X_season))\n",
    "    all_data_clean = pd.get_dummies(all_data_clean, columns=[c])\n",
    "    return all_data_clean\n",
    "\n",
    "\n",
    "def replace_outliers(all_data_clean, cols, threshold = 3):\n",
    "    for c in cols :\n",
    "        upper_limit = all_data_clean[c].mean() + threshold*all_data_clean[c].std()\n",
    "        lower_limit = all_data_clean[c].mean() - threshold*all_data_clean[c].std()    \n",
    "        all_data_clean[c] = np.where(\n",
    "            (all_data_clean[c]>upper_limit) & (all_data_clean['train']==0),\n",
    "            upper_limit,\n",
    "            np.where(\n",
    "                (all_data_clean[c]<lower_limit) & (all_data_clean['train']==0),\n",
    "                lower_limit,\n",
    "                all_data_clean[c]\n",
    "            ))\n",
    "    return all_data_clean\n",
    "\n",
    "def remove_outliers(all_data_clean, cols, threshold = 3):\n",
    "    for c in cols :\n",
    "        upper_limit = all_data_clean[c].mean() + threshold*all_data_clean[c].std()\n",
    "        lower_limit = all_data_clean[c].mean() - threshold*all_data_clean[c].std()    \n",
    "        all_data_clean[c] = np.where(\n",
    "            (all_data_clean[c]>upper_limit) & (all_data_clean['train']==1),\n",
    "            np.nan,\n",
    "            np.where(\n",
    "                (all_data_clean[c]<lower_limit) & (all_data_clean['train']==1),\n",
    "                np.nan,\n",
    "                all_data_clean[c]\n",
    "            ))\n",
    "    all_data_clean = all_data_clean.dropna()\n",
    "    return all_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score 0.49328444244850245\n",
      "Model score 0.4424460230408356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ncols = ['DE_RAIN','FR_RAIN','DE_WIND','FR_WIND','DE_TEMP','FR_TEMP']\\nall_data_clean = add_clusters(4,all_data_clean,cols,'season')\\n\\n\\n\\ncols = [ 'FR_HYDRO', 'FR_NUCLEAR', 'FR_SOLAR', 'FR_WINDPOW']\\nall_data_clean = add_clusters(4,all_data_clean,cols,'E_FR')\\n\\n\\ncols = [ 'DE_HYDRO', 'DE_NUCLEAR', 'DE_SOLAR', 'DE_WINDPOW', 'DE_LIGNITE']\\nall_data_clean = add_clusters(4,all_data_clean,cols,'E_DE')\\n\\n\\ncols = ['FR_GAS', 'FR_COAL','FR_RESIDUAL_LOAD']\\nall_data_clean = add_clusters(4,all_data_clean,cols,'N_FR')\\n\\ncols = ['DE_GAS', 'DE_COAL','DE_RESIDUAL_LOAD']\\nall_data_clean = add_clusters(4,all_data_clean,cols,'N_DE')\\n\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_clean = all_data.copy()\n",
    "all_data_clean['COUNTRY'] = all_data_clean['COUNTRY'].apply(lambda x: 0 if x =='FR' else 1)\n",
    "\n",
    "\n",
    "#all_data_clean = all_data_clean.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "\n",
    "#clean\n",
    "all_data_clean = clean_regression(all_data_clean)\n",
    "\n",
    "#remove features\n",
    "all_data_clean = remove_features(all_data_clean)\n",
    "\n",
    "\n",
    "columns = ['FR_DE_EXCHANGE', 'DE_NET_EXPORT',\n",
    "       'FR_NET_EXPORT', 'DE_GAS', 'FR_GAS', 'DE_COAL', 'FR_COAL', 'DE_HYDRO',\n",
    "       'FR_HYDRO', 'DE_NUCLEAR', 'FR_NUCLEAR', 'DE_SOLAR', 'FR_SOLAR',\n",
    "       'DE_WINDPOW', 'FR_WINDPOW', 'DE_LIGNITE', 'DE_RESIDUAL_LOAD',\n",
    "       'FR_RESIDUAL_LOAD', 'GAS_RET', 'COAL_RET', 'CARBON_RET']\n",
    "\n",
    "#all_data_clean = remove_outliers(all_data_clean, columns)\n",
    "\n",
    "#all_data_clean = replace_outliers(all_data_clean, columns)\n",
    "\n",
    "'''\n",
    "cols = ['DE_RAIN','FR_RAIN','DE_WIND','FR_WIND','DE_TEMP','FR_TEMP']\n",
    "all_data_clean = add_clusters(4,all_data_clean,cols,'season')\n",
    "\n",
    "\n",
    "\n",
    "cols = [ 'FR_HYDRO', 'FR_NUCLEAR', 'FR_SOLAR', 'FR_WINDPOW']\n",
    "all_data_clean = add_clusters(4,all_data_clean,cols,'E_FR')\n",
    "\n",
    "\n",
    "cols = [ 'DE_HYDRO', 'DE_NUCLEAR', 'DE_SOLAR', 'DE_WINDPOW', 'DE_LIGNITE']\n",
    "all_data_clean = add_clusters(4,all_data_clean,cols,'E_DE')\n",
    "\n",
    "\n",
    "cols = ['FR_GAS', 'FR_COAL','FR_RESIDUAL_LOAD']\n",
    "all_data_clean = add_clusters(4,all_data_clean,cols,'N_FR')\n",
    "\n",
    "cols = ['DE_GAS', 'DE_COAL','DE_RESIDUAL_LOAD']\n",
    "all_data_clean = add_clusters(4,all_data_clean,cols,'N_DE')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data_clean[\"FR_PRODUCTION\"] = all_data_clean['FR_GAS'] + all_data_clean['FR_COAL'] + all_data_clean['FR_HYDRO'] + all_data_clean['FR_NUCLEAR'] + all_data_clean['FR_SOLAR'] + all_data_clean['FR_WINDPOW']\n",
    "all_data_clean[\"DE_PRODUCTION\"] = all_data_clean['DE_GAS'] + all_data_clean['DE_COAL'] + all_data_clean['DE_HYDRO'] + all_data_clean['DE_NUCLEAR'] + all_data_clean['DE_SOLAR'] + all_data_clean['DE_WINDPOW'] + all_data_clean['DE_LIGNITE']\n",
    "\n",
    "all_data_clean['FR_NEED'] = all_data_clean[\"FR_CONSUMPTION\"] - all_data_clean['FR_PRODUCTION']  \n",
    "all_data_clean['DE_NEED'] = all_data_clean[\"DE_CONSUMPTION\"] - all_data_clean['DE_PRODUCTION'] \n",
    "\n",
    "all_data_clean['FR_NEED_RATIO'] =   all_data_clean['FR_CONSUMPTION'] / all_data_clean[\"FR_PRODUCTION\"]\n",
    "all_data_clean['DE_NEED_RATIO'] =  all_data_clean['DE_CONSUMPTION'] / all_data_clean[\"DE_PRODUCTION\"] \n",
    "\n",
    "all_data_clean['FR_NEED_RATIO_1'] =   all_data_clean['FR_NEED'] / all_data_clean[\"FR_PRODUCTION\"]\n",
    "all_data_clean['DE_NEED_RATIO_1'] =  all_data_clean['DE_NEED'] / all_data_clean[\"DE_PRODUCTION\"] \n",
    "\n",
    "\n",
    "all_data_clean['FR_NEED_RATIO_2'] =   all_data_clean[\"FR_PRODUCTION\"] / all_data_clean['FR_NEED']\n",
    "all_data_clean['DE_NEED_RATIO_2'] =   all_data_clean[\"DE_PRODUCTION\"] / all_data_clean['DE_NEED'] \n",
    "\n",
    "all_data_clean['FR_NEED_RATIO_3'] =   all_data_clean[\"FR_PRODUCTION\"] / all_data_clean['FR_CONSUMPTION']\n",
    "all_data_clean['DE_NEED_RATIO_3'] =   all_data_clean[\"DE_PRODUCTION\"] / all_data_clean['DE_CONSUMPTION'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_data_clean[all_data_clean['train'] == 1].drop(['train','TARGET','ID','DAY_ID'],axis=1)\n",
    "X_test = all_data_clean[all_data_clean['train'] == 0].drop(['train','TARGET','DAY_ID'],axis=1)\n",
    "id_train = all_data_clean[all_data_clean['train'] == 1]['ID']\n",
    "id_test = X_test['ID']\n",
    "X_test = X_test.drop('ID',axis=1)\n",
    "y_train = all_data_clean[all_data_clean['train'] == 1]['TARGET']\n",
    "\n",
    "\n",
    "X_train_FR = all_data_clean[(all_data_clean['train'] == 1) & (all_data_clean['COUNTRY'] == 0)].drop(['train','TARGET','ID','DAY_ID','COUNTRY'],axis=1)\n",
    "X_train_DE = all_data_clean[(all_data_clean['train'] == 1) & (all_data_clean['COUNTRY'] == 1)].drop(['train','TARGET','ID','DAY_ID','COUNTRY'],axis=1)\n",
    "id_train_DE = all_data_clean[(all_data_clean['train'] == 1) & (all_data_clean['COUNTRY'] == 1)]['ID']\n",
    "y_train_FR = all_data_clean[(all_data_clean['train'] == 1) & (all_data_clean['COUNTRY'] == 0)]['TARGET']\n",
    "y_train_DE = all_data_clean[(all_data_clean['train'] == 1) & (all_data_clean['COUNTRY'] == 1)]['TARGET']\n",
    "\n",
    "X_test_FR = all_data_clean[(all_data_clean['train'] == 0) & (all_data_clean['COUNTRY'] == 0)].drop(['train','TARGET','DAY_ID','COUNTRY'],axis=1)\n",
    "id_test_FR = X_test_FR['ID']\n",
    "X_test_FR = X_test_FR.drop('ID',axis=1)\n",
    "\n",
    "X_test_DE = all_data_clean[(all_data_clean['train'] == 0) & (all_data_clean['COUNTRY'] == 1)].drop(['train','TARGET','DAY_ID','COUNTRY'],axis=1)\n",
    "id_test_DE = X_test_DE['ID']\n",
    "X_test_DE = X_test_DE.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['COUNTRY'] = 2*X_train['COUNTRY'] - 1 \n",
    "X_test['COUNTRY'] = 2*X_test['COUNTRY'] - 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from fast_soft_sort.tf_ops import soft_rank, soft_sort\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_pred, y_true, sample_weights=None):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    \n",
    "    if np.any(y_true==0):\n",
    "        print(\"Found zeroes in y_true. MAPE undefined. Removing from set...\")\n",
    "        idx = np.where(y_true==0)\n",
    "        y_true = np.delete(y_true, idx)\n",
    "        y_pred = np.delete(y_pred, idx)\n",
    "        if type(sample_weights) != type(None):\n",
    "            sample_weights = np.array(sample_weights)\n",
    "            sample_weights = np.delete(sample_weights, idx)\n",
    "        \n",
    "    if type(sample_weights) == type(None):\n",
    "        return(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)\n",
    "    else:\n",
    "        sample_weights = np.array(sample_weights)\n",
    "        assert len(sample_weights) == len(y_true)\n",
    "        return(100/sum(sample_weights)*np.dot(\n",
    "                sample_weights, (np.abs((y_true - y_pred) / y_true))\n",
    "        ))\n",
    " \n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class CustomLinearModel(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Linear model: Y = XB, fit by minimizing the provided loss_function\n",
    "    with L2 regularization\n",
    "    \"\"\"\n",
    "    def __init__(self, X=None, Y=None, sample_weights=None, beta_init=None, \n",
    "                 regularization=0.01, alpha = 1, optim='BFGS'):\n",
    "        self.regularization = regularization\n",
    "        self.beta = None\n",
    "        self.sample_weights = sample_weights\n",
    "        self.beta_init = beta_init\n",
    "        self.alpha = alpha\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.optim = optim\n",
    "        self.coef_ = self.beta\n",
    "    \n",
    "       \n",
    "    def clip_beta(self):\n",
    "        self.beta[np.abs(self.beta) < 1e-4] = 0\n",
    "    \n",
    "    def cons_f(self,beta):\n",
    "        return np.var(self.X@beta)\n",
    "    def cons_J(x):\n",
    "        return [[2*x[0], 1], [2*x[0], -1]]\n",
    "    def cons_H(x, v):\n",
    "        return v[0]*np.array([[2, 0], [0, 0]]) + v[1]*np.array([[2, 0], [0, 0]])\n",
    "    \n",
    "    def mean_absolute_error(self, y_pred, y_true, sample_weights=None):\n",
    "        \n",
    "        \n",
    "        #values = tf.convert_to_tensor([y_pred], dtype=tf.float64)\n",
    "\n",
    "        #y_pred = soft_rank(values, regularization_strength=1).numpy().reshape(-1)\n",
    "        \n",
    "        #values = tf.convert_to_tensor([y_true], dtype=tf.float64)\n",
    "        \n",
    "        #y_true = soft_rank(values, regularization_strength=1).numpy().reshape(-1)\n",
    "        \n",
    "        #l = nn.HuberLoss()\n",
    "        #return l(torch.tensor([y_pred]),torch.tensor([y_true]))\n",
    "        return np.mean(np.abs(y_pred-y_true)**(self.alpha))\n",
    "    \n",
    "    def score(self,X,y_true):\n",
    "        y_pred = self.predict(X)\n",
    "        return my_custom_loss_func(y_pred,y_true)\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = X@self.beta\n",
    "        return(prediction)\n",
    "\n",
    "    def model_error(self):\n",
    "        y_pred = self.predict(self.X)\n",
    "        error = self.mean_absolute_error(\n",
    "            y_pred, self.Y, sample_weights=self.sample_weights\n",
    "        )\n",
    "        return(error)\n",
    "    \n",
    "    def l2_regularized_loss(self, beta):\n",
    "        self.beta = beta\n",
    "        return(self.model_error() + \\\n",
    "               sum(self.regularization*np.abs(np.array(self.beta))**2))\n",
    "    \n",
    "    def l1_regularized_loss(self, beta):\n",
    "        self.beta = beta\n",
    "        return(self.model_error() + \\\n",
    "               sum(self.regularization*np.abs(np.array(self.beta))))\n",
    "    \n",
    "    \n",
    "    def fit(self, X, Y, maxiter=10000):       \n",
    "        self.X = np.array(X)\n",
    "        self.Y = np.array(Y) \n",
    "        # Initialize beta estimates (you may need to normalize\n",
    "        # your data and choose smarter initialization values\n",
    "        # depending on the shape of your loss function)\n",
    "        if type(self.beta_init)==type(None):\n",
    "            # set beta_init = 1 for every feature\n",
    "            self.beta_init = np.array([1]*self.X.shape[1])\n",
    "        else: \n",
    "            self.beta_init = np.array([1]*self.X.shape[1])\n",
    "            self.beta = None\n",
    "            \n",
    "        if self.beta!=None and all(self.beta_init == self.beta):\n",
    "            print(\"Model already fit once; continuing fit with more itrations.\")\n",
    "        \n",
    "        #bounds = [(-0.2,0.2)]*len(self.beta_init)\n",
    "        res = minimize(self.l1_regularized_loss, self.beta_init, \n",
    "                       method=self.optim, options={'maxiter': maxiter,'disp':False}) #constraints=nonlinear_constraint)\n",
    "        self.beta = res.x\n",
    "        self.beta_init = self.beta\n",
    "        self.clip_beta()\n",
    "        self.coef_ = self.beta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_pred,y_true, sample_weights=None):\n",
    "    return np.mean((y_pred-y_true)**2)\n",
    "\n",
    "def mean_absolute_error(y_pred,y_true, sample_weights=None):\n",
    "    return np.mean(np.abs(y_pred-y_true))\n",
    "\n",
    "def error_corr(y_pred,y_true, sample_weights = None):\n",
    "    return  1 - spearmanr(y_true, y_pred).correlation\n",
    "    #return np.mean((y_pred-y_true)**2) - np.mean(y_pred**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2,include_bias = False)\n",
    "X_train_augmented  = poly.fit_transform(X_train)\n",
    "X_test_augmented = poly.transform(X_test)\n",
    "X_train_augmented = pd.DataFrame(columns=poly.get_feature_names(X_train.columns),data = np.array(X_train_augmented))\n",
    "X_test_augmented = pd.DataFrame(columns=poly.get_feature_names(X_train.columns),data = np.array(X_test_augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['DE_NET_EXPORT',\n",
    " 'DE_HYDRO',\n",
    " 'FR_WINDPOW',\n",
    " 'DE_RESIDUAL_LOAD',\n",
    "  'DE_FLOW_COAL',\n",
    " 'DE_FLOW_LIGNITE',\n",
    " 'CARBON_RET',\n",
    " 'DE_CONSUMPTION_RENEWABLE',\n",
    " 'COUNTRY_DE_CONSUMPTION_RENEWABLE',\n",
    " 'COUNTRY_CARBON_RET',\n",
    " 'COUNTRY_DE_RESIDUAL_LOAD',\n",
    " ]\n",
    "\n",
    "cols = ['DE_NET_EXPORT',\n",
    " 'DE_RESIDUAL_LOAD',\n",
    " 'DE_CONSUMPTION_RENEWABLE',\n",
    " 'COUNTRY DE_RESIDUAL_LOAD',\n",
    " 'DE_NET_EXPORT E_DE_0',\n",
    " 'DE_NET_EXPORT E_DE_3',\n",
    " 'DE_NET_EXPORT N_DE_1',\n",
    " 'FR_NET_EXPORT DE_WIND',\n",
    " 'FR_COAL FR_CONSUMPTION_RENEWABLE',\n",
    " 'FR_HYDRO N_FR_2',\n",
    " 'DE_SOLAR DE_FLOW_LIGNITE',\n",
    " 'FR_SOLAR E_FR_0',\n",
    " 'FR_SOLAR E_FR_1',\n",
    " 'DE_LIGNITE N_DE_0',\n",
    " 'GAS_RET CARBON_RET',\n",
    " 'DE_FLOW_LIGNITE FR_FLOW_GAS',\n",
    " 'FR_FLOW_GAS FR_NEED_RATIO',\n",
    " 'FR_FLOW_COAL N_DE_1',\n",
    " 'E_FR_0 FR_NEED_RATIO',\n",
    " 'N_FR_0 FR_NEED_RATIO']\n",
    "\n",
    "#cols =  keep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cols = ['DE_NET_EXPORT',\n",
    " 'COUNTRY DE_RESIDUAL_LOAD',\n",
    " 'DE_NET_EXPORT E_DE_1',\n",
    " 'FR_NET_EXPORT DE_WIND',\n",
    " 'FR_GAS E_DE_0',\n",
    " 'DE_LIGNITE N_DE_3',\n",
    " 'DE_WIND GAS_RET',\n",
    " 'FR_WIND DE_FLOW_LIGNITE',\n",
    " 'DE_CONSUMPTION_RENEWABLE N_FR_3',\n",
    " 'DE_CONSUMPTION_RENEWABLE N_DE_0',\n",
    " 'FR_FLOW_GAS FR_NEED_RATIO_1',\n",
    " 'FR_FLOW_COAL N_DE_0',\n",
    " 'FR_FLOW_COAL FR_NEED_RATIO',]\n",
    "\n",
    "\n",
    "cols = ['DE_NET_EXPORT',\n",
    " 'DE_HYDRO',\n",
    " 'FR_WINDPOW',\n",
    " 'DE_RESIDUAL_LOAD',\n",
    "  'DE_FLOW_COAL',\n",
    " 'DE_FLOW_LIGNITE',\n",
    " 'CARBON_RET',\n",
    " 'DE_CONSUMPTION_RENEWABLE',\n",
    " 'COUNTRY DE_CONSUMPTION_RENEWABLE',\n",
    " 'COUNTRY CARBON_RET',\n",
    " 'COUNTRY DE_RESIDUAL_LOAD',\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_COUNTRY = X_train_augmented['COUNTRY']\n",
    "#X_train_augmented = X_train_augmented[cols]\n",
    "#X_test_augmented = X_test_augmented[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_augmented,X_test_augmented])\n",
    "#X = X.drop(['COUNTRY'],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "cols = X.columns\n",
    "X_train_augmented[cols] = scaler.transform(X_train_augmented[cols])\n",
    "X_test_augmented[cols] = scaler.transform(X_test_augmented[cols])\n",
    "\n",
    "\n",
    "#X = pd.concat([X_train_augmented,X_test_augmented])\n",
    "#model = PCA(n_components=X.shape[1])\n",
    "#model.fit(X)\n",
    "#X_train_augmented = model.transform(X_train_augmented)\n",
    "#X_test_augmented = model.transform(X_test_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUNTRY', 'DE_CONSUMPTION', 'FR_CONSUMPTION', 'FR_DE_EXCHANGE',\n",
       "       'DE_NET_EXPORT', 'FR_NET_EXPORT', 'DE_GAS', 'FR_GAS', 'DE_COAL',\n",
       "       'FR_COAL',\n",
       "       ...\n",
       "       'FR_NEED_RATIO_2^2', 'FR_NEED_RATIO_2 DE_NEED_RATIO_2',\n",
       "       'FR_NEED_RATIO_2 FR_NEED_RATIO_3', 'FR_NEED_RATIO_2 DE_NEED_RATIO_3',\n",
       "       'DE_NEED_RATIO_2^2', 'DE_NEED_RATIO_2 FR_NEED_RATIO_3',\n",
       "       'DE_NEED_RATIO_2 DE_NEED_RATIO_3', 'FR_NEED_RATIO_3^2',\n",
       "       'FR_NEED_RATIO_3 DE_NEED_RATIO_3', 'DE_NEED_RATIO_3^2'],\n",
       "      dtype='object', length=1274)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_augmented.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:09<06:45,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': -0.24852749941652896, 'Adjusted R-Squared': 1.3812102406005384, 'RMSE': 1.0296925246251663, 'Time taken': 9.896729707717896}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/42 [00:26<09:08, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingRegressor', 'R-Squared': -0.46613604202419645, 'Adjusted R-Squared': 1.4476521931590272, 'RMSE': 1.1158238469851123, 'Time taken': 16.369807720184326}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/42 [00:28<05:26,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BayesianRidge', 'R-Squared': -0.022732415181328625, 'Adjusted R-Squared': 1.3122687087336433, 'RMSE': 0.9319433510051804, 'Time taken': 2.0373005867004395}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/42 [00:31<02:32,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': -2.1945555610142846, 'Adjusted R-Squared': 1.975386841375263, 'RMSE': 1.6470763324430693, 'Time taken': 3.2092154026031494}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.00015444419180421498, 'Adjusted R-Squared': 1.305375024968399, 'RMSE': 0.921599092075402, 'Time taken': 0.16318631172180176}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6/42 [00:31<01:39,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ElasticNet', 'R-Squared': -0.00015444419180421498, 'Adjusted R-Squared': 1.305375024968399, 'RMSE': 0.921599092075402, 'Time taken': 0.17092013359069824}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [04:33<47:04, 80.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.004756850696048476, 'Adjusted R-Squared': 1.3038754697669852, 'RMSE': 0.9193335343940559, 'Time taken': 241.16174983978271}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [04:33<31:17, 55.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': -1.6261891584912056, 'Adjusted R-Squared': 1.8018487389655524, 'RMSE': 1.4933840403531329, 'Time taken': 0.6029717922210693}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 9/42 [05:12<27:32, 50.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': -0.31031885216246957, 'Adjusted R-Squared': 1.4000768626479672, 'RMSE': 1.054865280706462, 'Time taken': 38.824410915374756}\n",
      "GammaRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [05:17<14:16, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -0.007682773938600063, 'Adjusted R-Squared': 1.307673633846007, 'RMSE': 0.9250611047396045, 'Time taken': 4.865265846252441}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12/42 [05:48<14:16, 28.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': -0.30276978874761706, 'Adjusted R-Squared': 1.397771923203678, 'RMSE': 1.0518222245876325, 'Time taken': 31.258305311203003}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 13/42 [06:21<14:20, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': -0.3351726930351917, 'Adjusted R-Squared': 1.4076654329144336, 'RMSE': 1.064822512610372, 'Time taken': 32.8627450466156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/42 [06:22<10:14, 21.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HuberRegressor', 'R-Squared': -2.370647829957197, 'Adjusted R-Squared': 2.0291527185729965, 'RMSE': 1.6918630019878231, 'Time taken': 1.4233283996582031}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 15/42 [06:23<07:08, 15.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsRegressor', 'R-Squared': -0.27531784295561224, 'Adjusted R-Squared': 1.389390079099152, 'RMSE': 1.0406812301776633, 'Time taken': 0.44309401512145996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 16/42 [06:23<04:56, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KernelRidge', 'R-Squared': -3.634979819733176, 'Adjusted R-Squared': 2.415188510533285, 'RMSE': 1.983957787600128, 'Time taken': 0.2633662223815918}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17/42 [06:24<03:28,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lars', 'R-Squared': -6710.758749325894, 'Adjusted R-Squared': 2050.286995183521, 'RMSE': 75.49647465256614, 'Time taken': 0.9155921936035156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18/42 [06:41<04:17, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LarsCV', 'R-Squared': -0.00015444419180421498, 'Adjusted R-Squared': 1.305375024968399, 'RMSE': 0.921599092075402, 'Time taken': 16.44150686264038}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 19/42 [06:41<02:55,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': -0.00015444419180421498, 'Adjusted R-Squared': 1.305375024968399, 'RMSE': 0.921599092075402, 'Time taken': 0.2105553150177002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [11:09<31:06, 84.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoCV', 'R-Squared': 0.0053502205141920944, 'Adjusted R-Squared': 1.3036942974249701, 'RMSE': 0.9190594375037462, 'Time taken': 267.9018135070801}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 21/42 [11:09<20:52, 59.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoLars', 'R-Squared': -0.00015444419180421498, 'Adjusted R-Squared': 1.305375024968399, 'RMSE': 0.921599092075402, 'Time taken': 0.23087501525878906}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 22/42 [11:23<15:22, 46.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.003950874871137433, 'Adjusted R-Squared': 1.3041215566479518, 'RMSE': 0.9197057101042377, 'Time taken': 14.311955690383911}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 23/42 [11:24<10:17, 32.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoLarsIC model failed to execute\n",
      "You are using LassoLarsIC in the case where the number of samples is smaller than the number of features. In this setting, getting a good estimate for the variance of the noise is not possible. Provide an estimate of the noise variance in the constructor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24/42 [11:25<06:58, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearRegression', 'R-Squared': -2.7062747991341682e+20, 'Adjusted R-Squared': 8.263011169487521e+19, 'RMSE': 15159834160.116022, 'Time taken': 1.6086022853851318}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 25/42 [11:30<04:58, 17.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearSVR', 'R-Squared': -2.237578564599242, 'Adjusted R-Squared': 1.9885229633714898, 'RMSE': 1.6581303236660567, 'Time taken': 4.238543272018433}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [11:31<03:25, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -0.8274632629089549, 'Adjusted R-Squared': 1.5579754634701521, 'RMSE': 1.2457555517187904, 'Time taken': 1.8673317432403564}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 27/42 [11:33<02:20,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'NuSVR', 'R-Squared': -0.0439920961182001, 'Adjusted R-Squared': 1.3187598818065815, 'RMSE': 0.9415797483155534, 'Time taken': 1.1417112350463867}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28/42 [11:33<01:33,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': -1.171090474861586, 'Adjusted R-Squared': 1.6628944277753612, 'RMSE': 1.3578364559705283, 'Time taken': 0.36270880699157715}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 29/42 [11:34<01:04,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': -0.014053037333682905, 'Adjusted R-Squared': 1.3096186527924565, 'RMSE': 0.9279804753567484, 'Time taken': 1.0070607662200928}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [11:34<00:27,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': -1.787308062771289, 'Adjusted R-Squared': 1.8510428306412336, 'RMSE': 1.5385123586506653, 'Time taken': 0.2556793689727783}\n",
      "PoissonRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32/42 [1:40:21<4:26:35, 1599.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuantileRegressor', 'R-Squared': -2.284400188578345e+84, 'Adjusted R-Squared': 6.974910411847815e+83, 'RMSE': 1.3928187268402794e+42, 'Time taken': 5326.820320606232}\n",
      "RANSACRegressor model failed to execute\n",
      "`min_samples` may not be larger than number of samples: n_samples = 1195.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 34/42 [1:42:58<1:59:40, 897.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': -0.3204810550561803, 'Adjusted R-Squared': 1.4031796664003502, 'RMSE': 1.0589478942177608, 'Time taken': 156.54905605316162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 35/42 [1:42:58<1:18:45, 675.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Ridge', 'R-Squared': -3.6626971646275583, 'Adjusted R-Squared': 2.4236513883801356, 'RMSE': 1.989881014742677, 'Time taken': 0.2204756736755371}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 37/42 [1:42:59<30:15, 363.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RidgeCV', 'R-Squared': -2.515892428272027, 'Adjusted R-Squared': 2.0734999422387954, 'RMSE': 1.7279305902288418, 'Time taken': 0.8325319290161133}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': -1.6061047852652667e+25, 'Adjusted R-Squared': 4.903885512387801e+24, 'RMSE': 3693137197676.0317, 'Time taken': 0.1792736053466797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 38/42 [1:43:00<17:27, 261.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.05304942560486858, 'Adjusted R-Squared': 1.3215253369162405, 'RMSE': 0.9456553447206277, 'Time taken': 1.1049737930297852}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 39/42 [1:43:02<09:22, 187.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': -2.7062747991341682e+20, 'Adjusted R-Squared': 8.263011169487521e+19, 'RMSE': 15159834160.116022, 'Time taken': 1.468318223953247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40/42 [1:43:02<04:26, 133.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'TweedieRegressor', 'R-Squared': -0.12424797856444814, 'Adjusted R-Squared': 1.343264239356768, 'RMSE': 0.9771012331153692, 'Time taken': 0.29684948921203613}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [1:43:09<01:36, 96.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': -0.4294813886636073, 'Adjusted R-Squared': 1.436460505964913, 'RMSE': 1.1017872855430424, 'Time taken': 6.778566360473633}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [1:43:14<00:00, 147.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': -0.34074029811397244, 'Adjusted R-Squared': 1.4093653779077497, 'RMSE': 1.067040331965073, 'Time taken': 5.305518627166748}\n",
      "                                                              Adjusted R-Squared  \\\n",
      "Model                                                                              \n",
      "QuantileRegressor             69749104118478153119995410593493848251829302250...   \n",
      "SGDRegressor                                        4903885512387801118670848.00   \n",
      "LinearRegression                                         82630111694875213824.00   \n",
      "TransformedTargetRegressor                               82630111694875213824.00   \n",
      "Lars                                                                     2050.29   \n",
      "Ridge                                                                       2.42   \n",
      "KernelRidge                                                                 2.42   \n",
      "RidgeCV                                                                     2.07   \n",
      "HuberRegressor                                                              2.03   \n",
      "LinearSVR                                                                   1.99   \n",
      "DecisionTreeRegressor                                                       1.98   \n",
      "PassiveAggressiveRegressor                                                  1.85   \n",
      "ExtraTreeRegressor                                                          1.80   \n",
      "OrthogonalMatchingPursuit                                                   1.66   \n",
      "MLPRegressor                                                                1.56   \n",
      "BaggingRegressor                                                            1.45   \n",
      "XGBRegressor                                                                1.44   \n",
      "LGBMRegressor                                                               1.41   \n",
      "HistGradientBoostingRegressor                                               1.41   \n",
      "RandomForestRegressor                                                       1.40   \n",
      "ExtraTreesRegressor                                                         1.40   \n",
      "GradientBoostingRegressor                                                   1.40   \n",
      "KNeighborsRegressor                                                         1.39   \n",
      "AdaBoostRegressor                                                           1.38   \n",
      "TweedieRegressor                                                            1.34   \n",
      "SVR                                                                         1.32   \n",
      "NuSVR                                                                       1.32   \n",
      "BayesianRidge                                                               1.31   \n",
      "OrthogonalMatchingPursuitCV                                                 1.31   \n",
      "GaussianProcessRegressor                                                    1.31   \n",
      "Lasso                                                                       1.31   \n",
      "LarsCV                                                                      1.31   \n",
      "ElasticNet                                                                  1.31   \n",
      "DummyRegressor                                                              1.31   \n",
      "LassoLars                                                                   1.31   \n",
      "LassoLarsCV                                                                 1.30   \n",
      "ElasticNetCV                                                                1.30   \n",
      "LassoCV                                                                     1.30   \n",
      "\n",
      "                                                                       R-Squared  \\\n",
      "Model                                                                              \n",
      "QuantileRegressor             -2284400188578344953084270272191314747219684763...   \n",
      "SGDRegressor                                      -16061047852652666516668416.00   \n",
      "LinearRegression                                       -270627479913416818688.00   \n",
      "TransformedTargetRegressor                             -270627479913416818688.00   \n",
      "Lars                                                                    -6710.76   \n",
      "Ridge                                                                      -3.66   \n",
      "KernelRidge                                                                -3.63   \n",
      "RidgeCV                                                                    -2.52   \n",
      "HuberRegressor                                                             -2.37   \n",
      "LinearSVR                                                                  -2.24   \n",
      "DecisionTreeRegressor                                                      -2.19   \n",
      "PassiveAggressiveRegressor                                                 -1.79   \n",
      "ExtraTreeRegressor                                                         -1.63   \n",
      "OrthogonalMatchingPursuit                                                  -1.17   \n",
      "MLPRegressor                                                               -0.83   \n",
      "BaggingRegressor                                                           -0.47   \n",
      "XGBRegressor                                                               -0.43   \n",
      "LGBMRegressor                                                              -0.34   \n",
      "HistGradientBoostingRegressor                                              -0.34   \n",
      "RandomForestRegressor                                                      -0.32   \n",
      "ExtraTreesRegressor                                                        -0.31   \n",
      "GradientBoostingRegressor                                                  -0.30   \n",
      "KNeighborsRegressor                                                        -0.28   \n",
      "AdaBoostRegressor                                                          -0.25   \n",
      "TweedieRegressor                                                           -0.12   \n",
      "SVR                                                                        -0.05   \n",
      "NuSVR                                                                      -0.04   \n",
      "BayesianRidge                                                              -0.02   \n",
      "OrthogonalMatchingPursuitCV                                                -0.01   \n",
      "GaussianProcessRegressor                                                   -0.01   \n",
      "Lasso                                                                      -0.00   \n",
      "LarsCV                                                                     -0.00   \n",
      "ElasticNet                                                                 -0.00   \n",
      "DummyRegressor                                                             -0.00   \n",
      "LassoLars                                                                  -0.00   \n",
      "LassoLarsCV                                                                 0.00   \n",
      "ElasticNetCV                                                                0.00   \n",
      "LassoCV                                                                     0.01   \n",
      "\n",
      "                                                                        RMSE  \\\n",
      "Model                                                                          \n",
      "QuantileRegressor             1392818726840279426155317763174109663985664.00   \n",
      "SGDRegressor                                                3693137197676.03   \n",
      "LinearRegression                                              15159834160.12   \n",
      "TransformedTargetRegressor                                    15159834160.12   \n",
      "Lars                                                                   75.50   \n",
      "Ridge                                                                   1.99   \n",
      "KernelRidge                                                             1.98   \n",
      "RidgeCV                                                                 1.73   \n",
      "HuberRegressor                                                          1.69   \n",
      "LinearSVR                                                               1.66   \n",
      "DecisionTreeRegressor                                                   1.65   \n",
      "PassiveAggressiveRegressor                                              1.54   \n",
      "ExtraTreeRegressor                                                      1.49   \n",
      "OrthogonalMatchingPursuit                                               1.36   \n",
      "MLPRegressor                                                            1.25   \n",
      "BaggingRegressor                                                        1.12   \n",
      "XGBRegressor                                                            1.10   \n",
      "LGBMRegressor                                                           1.07   \n",
      "HistGradientBoostingRegressor                                           1.06   \n",
      "RandomForestRegressor                                                   1.06   \n",
      "ExtraTreesRegressor                                                     1.05   \n",
      "GradientBoostingRegressor                                               1.05   \n",
      "KNeighborsRegressor                                                     1.04   \n",
      "AdaBoostRegressor                                                       1.03   \n",
      "TweedieRegressor                                                        0.98   \n",
      "SVR                                                                     0.95   \n",
      "NuSVR                                                                   0.94   \n",
      "BayesianRidge                                                           0.93   \n",
      "OrthogonalMatchingPursuitCV                                             0.93   \n",
      "GaussianProcessRegressor                                                0.93   \n",
      "Lasso                                                                   0.92   \n",
      "LarsCV                                                                  0.92   \n",
      "ElasticNet                                                              0.92   \n",
      "DummyRegressor                                                          0.92   \n",
      "LassoLars                                                               0.92   \n",
      "LassoLarsCV                                                             0.92   \n",
      "ElasticNetCV                                                            0.92   \n",
      "LassoCV                                                                 0.92   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "QuantileRegressor                 5326.82  \n",
      "SGDRegressor                         0.18  \n",
      "LinearRegression                     1.61  \n",
      "TransformedTargetRegressor           1.47  \n",
      "Lars                                 0.92  \n",
      "Ridge                                0.22  \n",
      "KernelRidge                          0.26  \n",
      "RidgeCV                              0.83  \n",
      "HuberRegressor                       1.42  \n",
      "LinearSVR                            4.24  \n",
      "DecisionTreeRegressor                3.21  \n",
      "PassiveAggressiveRegressor           0.26  \n",
      "ExtraTreeRegressor                   0.60  \n",
      "OrthogonalMatchingPursuit            0.36  \n",
      "MLPRegressor                         1.87  \n",
      "BaggingRegressor                    16.37  \n",
      "XGBRegressor                         6.78  \n",
      "LGBMRegressor                        5.31  \n",
      "HistGradientBoostingRegressor       32.86  \n",
      "RandomForestRegressor              156.55  \n",
      "ExtraTreesRegressor                 38.82  \n",
      "GradientBoostingRegressor           31.26  \n",
      "KNeighborsRegressor                  0.44  \n",
      "AdaBoostRegressor                    9.90  \n",
      "TweedieRegressor                     0.30  \n",
      "SVR                                  1.10  \n",
      "NuSVR                                1.14  \n",
      "BayesianRidge                        2.04  \n",
      "OrthogonalMatchingPursuitCV          1.01  \n",
      "GaussianProcessRegressor             4.87  \n",
      "Lasso                                0.21  \n",
      "LarsCV                              16.44  \n",
      "ElasticNet                           0.17  \n",
      "DummyRegressor                       0.16  \n",
      "LassoLars                            0.23  \n",
      "LassoLarsCV                         14.31  \n",
      "ElasticNetCV                       241.16  \n",
      "LassoCV                            267.90  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "offset = int(X_train_augmented.shape[0] * 0.8)\n",
    "\n",
    "X_train_m, y_train_m = X_train_augmented[:offset], y_train[:offset]\n",
    "X_test_m, y_test_m = X_train_augmented[offset:], y_train[offset:]\n",
    "\n",
    "reg = LazyRegressor(verbose=1, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train_m, X_test_m, y_train_m, y_test_m)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbccc05dc4c888eb06191605395e1f3420714a4fab311b29cb06bebce36a9c54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
